from integralstor import audit, rsync, datetime_utils, scheduler_utils, tasks_utils, db, config, command, networking, system_info

import crontab
from textwrap import wrap


def _replication_modes():
    """Maintains the list of available modes for remote replication

    args:       None
    returns:    A list containing available modes
    """
    # Modularity at the cost of redundancy
    modes = []
    try:
        modes = ['zfs', 'rsync']
    except Exception, e:
        return None, str(e)
    else:
        return modes, None


def get_replication_modes():
    """Gets the available modes of remote replication

    args:       None
    returns:    A list containing available modes
    """

    modes = []
    try:
        ret, err = _replication_modes()
        if err:
            raise Exception(err)
        if not ret:
            raise Exception('No replication mode found')
        modes = ret
    except Exception, e:
        return None, str(e)
    else:
        return modes, None


def get_snapshot_sync_cmd_post_rsync(remote_replication_id, source_snap_name):
    """Generate the commands to run on the host machines to sync ZFS
    snapshots post rsync replication run.

    Rename the temporary snapshot on the source node, create a snapshot
    by the same name on the target node.

    args:       remote_replication_id,
                source_snap_name # a string with just the snap name
                                 # without FS prefix
    returns:    a dict with two string fields:
                    rename_snap_cmd # to rename on the source host
                    create_snap_cmd # to create on the target host
    """
    try:
        rr, err = get_remote_replications(remote_replication_id)
        if err:
            raise Exception('Could not fetch replication details: %s' % err)

        replication = rr[0]
        rsync_entries = replication['rsync'][0]
        rsync_type = rsync_entries['rsync_type']
        mode = replication['mode']
        if mode != 'rsync':
            raise Exception('Invalid replication mode')
        is_between_integralstor = rsync_entries['is_between_integralstor']
        rsync_type = rsync_entries['rsync_type']
        remote_ip = rsync_entries['target_ip']
        remote_user_name = rsync_entries['target_user_name']
        ssh_cmd = 'ssh %s@%s' % (remote_user_name, remote_ip)

        fs_names, err = get_source_target_fs_names(remote_replication_id)
        if err:
            raise Exception('Could not get filesystem names: %s' % err)
        source_fs = fs_names['source_fs']
        target_fs = fs_names['target_fs']
        new_snap_name = source_snap_name.split('_tmp')

        source_snap_old_name = '%s@%s' % (source_fs, source_snap_name)
        source_snap_new_name = '%s@%s' % (source_fs, new_snap_name[0])
        target_snap_new_name = '%s@%s' % (target_fs, new_snap_name[0])
        rename_snap = 'sudo zfs rename %s %s' % (
            source_snap_old_name, source_snap_new_name)
        create_snap = 'sudo zfs snapshot %s' % target_snap_new_name
        rename_snap_cmd = ''
        create_snap_cmd = ''

        if rsync_type == 'pull':
            create_snap_cmd = '%s' % (create_snap)
            rename_snap_cmd = '%s \\"%s\\"' % (ssh_cmd, rename_snap)
            # If the source is not an integralstor unit, digress from
            # snapshotting
            if is_between_integralstor == 'False':
                rename_snap_cmd = ''
        elif rsync_type == 'push':
            rename_snap_cmd = '%s' % (rename_snap)
            create_snap_cmd = '%s \\"%s\\"' % (ssh_cmd, create_snap)
            # If the target is not an integralstor unit, digress from
            # snapshotting
            if is_between_integralstor == 'False':
                create_snap_cmd = ''
        elif rsync_type == 'local':
            rename_snap_cmd = '%s' % (rename_snap)
            create_snap_cmd = ''

    except Exception, e:
        return None, str(e)
    else:
        return {'rename_snap_cmd': rename_snap_cmd, 'create_snap_cmd': create_snap_cmd}, None


def sync_snapshot_prior_rsync(remote_replication_id):
    """Syncs ZFS snapshot between the hosts involved in the rsync
    replication prior to the actual data transfer

    Every rsync replication moves data from a snapshot, not the live
    filesystem. When called prior to the replication run, this function
    will create a temporary snapshot specific to this replication id on
    the source. If a temporary snapshot already exists, it will not
    create a new snapshot. 

    The rsync shell script which runs the actual replication does the
    snapshot sync post replication run. On a successful run, the
    temporary snapshot is renamed on the source side. So, if there's a
    temporary snapshot present, it's safe to assume that the previous
    run for this replication id did not complete successfully.

    args:       remote_replication_id
    returns:    a string containing the temporary snapshot name for 
                the source.
                pattern:      A_B_C_tmp
                    where, A: 'rrr_' for rsync remote repl.
                           B: remote_replication_id
                           C: datetime_utils str_format='%Y%m%d%H%M'
    """
    source_snap_name = None
    try:
        run_as_user_name = 'replicator'
        now_local_epoch, err = datetime_utils.get_epoch(when='now')
        if err:
            raise Exception(err)
        now_local_str, err = datetime_utils.convert_from_epoch(
            now_local_epoch, return_format='str', str_format='%Y%m%d%H%M', to='local')
        if err:
            raise Exception(err)

        rr, err = get_remote_replications(remote_replication_id)
        if err:
            raise Exception('Could not fetch replication details: %s' % err)

        replication = rr[0]
        rsync_entries = replication['rsync'][0]
        rsync_type = rsync_entries['rsync_type']
        mode = replication['mode']
        if mode != 'rsync':
            raise Exception('Invalid replication mode')

        is_between_integralstor = rsync_entries['is_between_integralstor']
        rsync_type = rsync_entries['rsync_type']
        remote_ip = rsync_entries['target_ip']
        remote_user_name = rsync_entries['target_user_name']
        ssh_cmd = 'ssh -l replicator -i /home/replicator/.ssh/id_rsa -o ServerAliveInterval=300 -o ServerAliveCountMax=3 %s@%s' % (
            remote_user_name, remote_ip)
        # ssh_cmd = 'ssh %s@%s' % (remote_user_name, remote_ip)

        fs_names, err = get_source_target_fs_names(remote_replication_id)
        if err:
            raise Exception('Could not get filesystem names: %s' % err)
        source_fs = fs_names['source_fs']
        # 'rrr' identifies rsync remote replication
        new_snap_name = 'rrr_%s_%s_tmp' % (
            remote_replication_id, now_local_str)
        new_snap_full_name = '%s@%s' % (source_fs, new_snap_name)
        get_snap = 'sudo zfs list -H -r %s -t snapshot -o name | grep -e .*@rrr_%s_[0-9]*_tmp$' % (
            source_fs, remote_replication_id)
        create_snap = 'sudo zfs snapshot %s' % new_snap_full_name
        get_snap_cmd = ''
        create_snap_cmd = ''

        if rsync_type == 'pull':
            get_snap_cmd = "%s '%s'" % (ssh_cmd, get_snap)
            create_snap_cmd = "%s '%s'" % (ssh_cmd, create_snap)
            # If the source is not an integralstor unit, digress from
            # snapshotting
            if is_between_integralstor == 'False':
                get_snap_cmd = create_snap_cmd = None
        elif rsync_type in ['push', 'local']:
            get_snap_cmd = '%s' % (get_snap)
            create_snap_cmd = '%s' % (create_snap)

        if get_snap_cmd and create_snap_cmd:
            ret, err = command.get_command_output(
                get_snap_cmd, True, True, run_as_user_name)
            # If any snap is returned, do not create a new snapshot,
            # proceed with the existing one since the previous
            # replication attempt is not complete yet. Else, create a
            # a new snapshot to seed this attempt
            if ret and not err:
                split_name = ret[0].split('@')
                source_snap_name = split_name[1]
            else:
                ret1, err1 = command.get_command_output(
                    create_snap_cmd, True, True, run_as_user_name)
                if err1:
                    raise Exception(err1)
                source_snap_name = new_snap_name

    except Exception, e:
        return None, str(e)
    else:
        return source_snap_name, None


def get_source_target_fs_names(remote_replication_id):
    """Returns the ZFS file system names of source and target hosts
    involved in the replication. 

    args:       remote_replication_id
    returns:    a dict with 'source_fs' & 'target_fs' fields
                    source_fs & target_fs are strings of the form
                    POOL_NAME/FS_NAME or POOL_NAME if it's the root
                    file system 
    """
    try:
        source_fs = None
        target_fs = None
        rr, err = get_remote_replications(remote_replication_id)
        if err:
            raise Exception('Could not fetch replication details: %s' % err)

        replication = rr[0]
        rsync_entries = replication['rsync'][0]
        mode = replication['mode']
        if mode != 'rsync':
            raise Exception('Invalid replication mode')

        source_path = rsync_entries['source_path']
        target_path = rsync_entries['target_path']

        source_dirs = [d for d in source_path[1:].split('/')]
        if source_dirs[0] and source_dirs[1]:
            source_fs = '%s/%s' % (source_dirs[0], source_dirs[1])
        elif source_dirs[0]:
            source_fs = '%s' % (source_dirs[0])
        target_dirs = [d for d in target_path[1:].split('/')]
        if target_dirs[0] and target_dirs[1]:
            target_fs = '%s/%s' % (target_dirs[0], target_dirs[1])
        elif target_dirs[0]:
            target_fs = '%s' % (target_dirs[0])

    except Exception, e:
        return None, str(e)
    else:
        return {'source_fs': source_fs, 'target_fs': target_fs}, None


def add_remote_replication(mode, entries):
    """Add remote replication entries to respective tables

    - add replication entry to remote_replications table
    - call replication mode(zfs,rsync) specific functions to add other
      required entries to respective mode specific tables

    args:       - mode           # string type replication mode
                - entries        # A dictionary with required mode
                                   specific values

    returns:    - a dictionary containing cron_task_id and 
                  remote_replication_id if the run was successful, None
                  otherwise.
                - Error string if the run failed or if exceptions were
                  raised, None otherwise.
    """
    remote_replication_id = None
    try:
        if not (mode and entries):
            raise Exception('Invalid parameters')

        modes, err = get_replication_modes()
        if err:
            raise Exception(err)
        if mode not in modes:
            raise Exception('Invalid replication mode: %s' % mode)

        if ('description' and 'schedule') not in entries:
            raise Exception('Invalid parameters')

        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        is_one_shot = False
        if 'is_one_shot' in entries and entries['is_one_shot'] == True:
            is_one_shot = True

        # Since cron_task_id is a required parameter pass -1 to
        # represent its unavailability. Update when available.
        cron_task_id = -1

        # Insert in to remote_replications is followed by insert in to
        # appropriate mode specific replication table.
        rr_cmd = "insert into remote_replications (cron_task_id,mode,is_one_shot) values ('%d','%s','%s')" % (
            cron_task_id, mode, is_one_shot)
        remote_replication_id, err = db.execute_iud(
            db_path, [[rr_cmd], ], get_rowid=True)
        if err:
            raise Exception(err)

        if mode == 'zfs':
            ids, err = _add_zfs_remote_replication(
                remote_replication_id, entries)
            if err:
                raise Exception(err)
            if ids and ids['cron_task_id']:
                cron_task_id = ids['cron_task_id']
        elif mode == 'rsync':
            ids, err = _add_rsync_remote_replication(
                remote_replication_id, entries)
            if err:
                raise Exception(err)
            if ids and ids['cron_task_id']:
                cron_task_id = ids['cron_task_id']

        if (not remote_replication_id) or (not cron_task_id):
            raise Exception(
                'remote_replication_id or cron_task_id is unavailable')

    except Exception, e:
        return None, 'Error adding a remote replication task: %s' % e
    else:
        return {'remote_replication_id': remote_replication_id, 'cron_task_id': cron_task_id}, None


def _add_rsync_remote_replication(remote_replication_id, entries):
    """Add rsync replication and cron entries

    - add rsync replication fields to rsync_replications table
    - add cron entry that runs rsync replication at the scheduled time

    args:       - remote_replication_id 
                - entries        # A dictionary with required rsync
                                   specific values

    returns:    - a dictionary containing cron_task_id and 
                  rsync_remote_replication_id if the run was successful
                  None otherwise.
                - Error string if the run failed or if exceptions were
                  raised, None otherwise.
    """
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        py_scripts_path, err = config.get_python_scripts_path()
        if err:
            raise Exception(err)

        if ('rsync_type' and 'short_switches' and 'long_switches' and 'source_path' and 'target_path' and 'target_ip' and 'is_between_integralstor' and 'target_user_name' and 'description' and 'schedule') not in entries:
            raise Exception('Invalid parameters')

        rsync_repl_cmd = "insert into rsync_replications (remote_replication_id,rsync_type,short_switches,long_switches,source_path,target_path,target_ip,is_between_integralstor,target_user_name) values ('%d','%s','%s','%s','%s','%s','%s','%s','%s')" % (
            remote_replication_id, entries['rsync_type'], entries['short_switches'], entries['long_switches'], entries['source_path'], entries['target_path'], entries['target_ip'], entries['is_between_integralstor'], entries['target_user_name'])

        rsync_remote_replication_id, err = db.execute_iud(
            db_path, [[rsync_repl_cmd], ], get_rowid=True)
        if err:
            # If insert to rsync_replications table fails, remove the
            # appropriate entry from remote_replications to avoid
            # dangling/invalid entries in the table.
            revert_cmd = "delete from remote_replications where remote_replication_id='%s'" % remote_replication_id
            rowid, er = db.execute_iud(
                db_path, [[revert_cmd], ], get_rowid=False)
            # revert is a best effort, so, no exceptions raised.
            raise Exception('%s' % err)

        schedule = entries['schedule']
        cmd = '%s/run_rsync_remote_replication.py %s' % (
            py_scripts_path, remote_replication_id)

        # this cron entry executes the rsync replication python script
        # which in turn calls another function to run(queues) the rsync
        # replication of the specified remote_replication_id
        cron_task_id, err = scheduler_utils.create_cron_task(
            cmd, entries['description'], schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
        if err:
            raise Exception(err)

        # Update cron_task_id which was previously set as -1
        cmd = "update remote_replications set cron_task_id='%d' where remote_replication_id='%s'" % (
            cron_task_id, remote_replication_id)
        rowid, err = db.execute_iud(db_path, [[cmd], ], get_rowid=True)
        if err:
            raise Exception(
                'Scheduling remote replication unsuccessfull: %s' % err)

        if (not rsync_remote_replication_id) or (not cron_task_id):
            raise Exception(
                'rsync_remote_replication_id or cron_task_id is unavailable')

    except Exception, e:
        return None, 'Error adding rsync remote replication task: %s' % e
    else:
        return {'rsync_remote_replication_id': rsync_remote_replication_id, 'cron_task_id': cron_task_id}, None


def _add_zfs_remote_replication(remote_replication_id, entries):
    """Add ZFS replication and cron entries

    - add ZFS replication fields to zfs_replications table
    - add cron entry that runs ZFS replication at the scheduled time

    args:       - remote_replication_id 
                - entries        # A dictionary with required ZFS
                                   specific values

    returns:    - a dictionary containing cron_task_id and 
                  zfs_remote_replication_id if the run was successful
                  None otherwise.
                - Error string if the run failed or if exceptions were
                  raised, None otherwise.
    """
    try:
        if ('source_dataset' and 'target_pool' and 'target_ip' and 'target_user_name') not in entries:
            raise Exception('Invalid parameters')

        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        py_scripts_path, err = config.get_python_scripts_path()
        if err:
            raise Exception(err)

        zfs_repl_cmd = "insert into zfs_replications (remote_replication_id,source_dataset,target_pool,target_ip,target_user_name) values ('%d','%s','%s','%s','%s')" % (
            remote_replication_id, entries['source_dataset'], entries['target_pool'], entries['target_ip'], entries['target_user_name'])

        zfs_remote_replication_id, err = db.execute_iud(
            db_path, [[zfs_repl_cmd], ], get_rowid=True)
        if err:
            # If insert to zfs_replications table fails, remove the
            # appropriate entry from remote_replications to avoid
            # dangling/invalid entries in the table.
            revert_cmd = "delete from remote_replications where remote_replication_id='%s'" % remote_replication_id
            rowid, er = db.execute_iud(
                db_path, [[revert_cmd], ], get_rowid=False)
            # revert is a best effort, so, no exceptions raised.
            raise Exception('%s' % err)

        schedule = entries['schedule']
        cmd = '%s/run_zfs_remote_replication.py %s' % (
            py_scripts_path, remote_replication_id)

        # this cron entry executes the ZFS replication python script
        # which in turn calls another function to run(queues) the ZFS
        # replication of the specified remote_replication_id
        cron_task_id, err = scheduler_utils.create_cron_task(
            cmd, entries['description'], schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
        if err:
            raise Exception(err)

        # Update cron_task_id which was previously set as -1
        cmd = "update remote_replications set cron_task_id='%d' where remote_replication_id='%s'" % (
            cron_task_id, remote_replication_id)
        rowid, err = db.execute_iud(db_path, [[cmd], ], get_rowid=True)
        if err:
            raise Exception(
                'Scheduling remote replication unsuccessfull: %s' % err)

        if (not zfs_remote_replication_id) or (not cron_task_id):
            raise Exception(
                'zfs_remote_replication_id or cron_task_id is unavailable')

    except Exception, e:
        return None, 'Error adding zfs remote replication task: %s' % e
    else:
        return {'zfs_remote_replication_id': zfs_remote_replication_id, 'cron_task_id': cron_task_id}, None


def update_remote_replication_schedule(remote_replication_id, schedule):
    try:
        if not (remote_replication_id and schedule):
            raise Exception('Invalid arguments')

        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        replications, err = get_remote_replications(
            remote_replication_id)
        if err:
            raise Exception(err)
        if not replications:
            raise Exception('Specified replication definition not found')

        cron_task_id = None
        if 'cron_task_id' in replications[0]:
            cron_task_id = replications[0]['cron_task_id']
        else:
            raise Exception('Cron task ID unavailable')

        is_update, err = scheduler_utils.update_cron_schedule(
            cron_task_id, 'root', schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
        if err:
            raise Exception(err)

    except Exception, e:
        return False, 'Error updating remote replication schedule: %s' % e
    else:
        return True, None


def update_rsync_remote_replication_pause_schedule(remote_replication_id, schedule=None):
    try:
        if not (remote_replication_id):
            raise Exception('Invalid arguments')

        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        replications, err = get_remote_replications(
            remote_replication_id)
        if err:
            raise Exception(err)
        if not replications:
            raise Exception('Specified replication definition not found')
        replication = replications[0]

        pause_cron_task_id = None
        if 'pause_cron_task_id' in replication:
            pause_cron_task_id = replication['pause_cron_task_id']
        elif 'pause_cron_task_id' not in replication:
            raise Exception('Field unavailable')

        if schedule and int(pause_cron_task_id) != -1:
            # When schedule is available and pause_cron_task_id is not -1,
            # it's an update since a pause cron job is already available.
            is_update, err = scheduler_utils.update_cron_schedule(
                pause_cron_task_id, 'root', schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
            if err:
                raise Exception(err)
        elif schedule and int(pause_cron_task_id) == -1:
            # When schedule is available and pause_cron_task_id equals -1,
            # create a pause cron job because it doesn't exist already.
            py_scripts_path, err = config.get_python_scripts_path()
            if err:
                raise Exception(err)
            command = '%s/pause_rsync_remote_replication.py %s' % (
                py_scripts_path, remote_replication_id)
            rep_cron_tasks, err = scheduler_utils.get_cron_tasks(replication['cron_task_id'])
            if err:
                raise Exception(err)
            description = rep_cron_tasks[0]['description']
            pause_cron_task_id, err = scheduler_utils.create_cron_task(
                command, description, schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
            if err:
                raise Exception(err)

            # pause_cron_task_id which defaults as -1(dummy), update with actual id.
            cmd = "update remote_replications set pause_cron_task_id='%d' where remote_replication_id='%s'" % (
                pause_cron_task_id, remote_replication_id)
            rowid, err = db.execute_iud(db_path, [[cmd], ], get_rowid=True)
            if err:
                raise Exception(
                    'Update attempt of replication pause schedule unsuccessfull: %s' % err)

        elif pause_cron_task_id and int(pause_cron_task_id) != -1 and schedule is None:
            # When schedule is none, remove the cron entry
            cron = crontab.CronTab('root')
            cron.remove_all(comment=str(pause_cron_task_id))
            cron.write()

            # reset cron_task_id to dummy value -1
            cmd = "update remote_replications set pause_cron_task_id=-1 where remote_replication_id='%s'" % (
                remote_replication_id)
            rowid, err = db.execute_iud(db_path, [[cmd], ], get_rowid=True)
            if err:
                raise Exception(
                    'Update attempt of replication pause schedule unsuccessfull: %s' % err)
            cmd_list = []
            cmd_list.append(
                ['delete from cron_tasks where cron_task_id=%d' % pause_cron_task_id])
            ret, err = db.execute_iud(db_path, cmd_list)
            if err:
                raise Exception(err)


        elif pause_cron_task_id and int(pause_cron_task_id) == -1 and schedule is None:
            # do nothing- this is useful for cleanup
            pass
        else:
            raise Exception("Undefined condition")

    except Exception, e:
        return None, "Error updating remote replication's pause schedule: %s" % e
    else:
        return pause_cron_task_id, None


def delete_remote_replication(remote_replication_id):
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        replications, err = get_remote_replications(
            remote_replication_id)
        # replications must contain only one entry since
        # remote_replication_id will have a single unique entry.
        if err:
            raise Exception(err)
        if not replications:
            raise Exception(
                'Specified remote replication not found')

        if replications[0]['mode'] == 'rsync':
            remove_pause_schedule, err = update_rsync_remote_replication_pause_schedule(remote_replication_id)
            if err:
                raise Exception(err)
        elif replications[0]['mode'] == 'zfs':
            # TODO: handle this when ZFS pause/resume is brought in
            pass

        cron_remove, err = scheduler_utils.delete_cron(
            int(replications[0]['cron_task_id']))
        if err:
            raise Exception(err)

    except Exception, e:
        return False, 'Error deleting remote replication task: %s' % e
    else:
        return True, None


def delete_all_remote_replications():
    """Delete all scheduled remote replications and respective cron table entries.

    """
    error_list = []
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        replications, err = get_remote_replications()
        if err:
            raise Exception(err)
        for replication in replications:
            ret, err = delete_remote_replication(
                int(replication['remote_replication_id']))
            if err:
                error_list.append(err)

        if error_list:
            raise Exception(str(error_list))
    except Exception, e:
        return False, 'Error deleting remote replication tasks : %s' % e
    else:
        return True, None


def get_remote_replications(remote_replication_id=None):
    replications = []
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        if remote_replication_id is not None:
            cmd = "select * from remote_replications where remote_replication_id='%s'" % remote_replication_id
        else:
            cmd = "select * from remote_replications"
        replications, err = db.get_multiple_rows(db_path, cmd)
        if err:
            raise Exception(err)

        if replications is not None:
            for replication in replications:
                cron_tasks, err = scheduler_utils.get_cron_tasks(
                    replication['cron_task_id'])
                if err:
                    raise Exception(err)
                if not cron_tasks:
                    raise Exception('Specified replication schedule not found')
                pause_cron_tasks, err = scheduler_utils.get_cron_tasks(
                    replication['pause_cron_task_id'])
                if err:
                    raise Exception(err)
                replication['schedule_description'] = cron_tasks[0]['schedule_description']
                if replication['is_one_shot'] == 'True':
                    replication['schedule_description'] = "[One time] %s" % replication['schedule_description']
                if 'schedule_description' in pause_cron_tasks[0] and pause_cron_tasks[0]['schedule_description']:
                    replication['pause_schedule_description'] = pause_cron_tasks[0]['schedule_description']
                else:
                    replication['pause_schedule_description'] = ''
                replication['description'] = cron_tasks[0]['description']
                mode_cmd = "select * from %s_replications where remote_replication_id='%s'" % (
                    replication['mode'], replication['remote_replication_id'])
                mode_repl, err = db.get_multiple_rows(db_path, mode_cmd)
                if err:
                    raise Exception(err)
                if mode_repl is not None:
                    mode = replication['mode']
                    replication[mode] = mode_repl

    except Exception, e:
        return None, 'Error retrieving remote replications : %s' % e
    else:
        return replications, None


def get_remote_replications_with(mode, entries):
    replications = []
    repls = []
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        modes, err = get_replication_modes()
        if err:
            raise Exception(err)
        if mode and mode not in modes:
            raise Exception('Invalid replication mode: %s' % mode)
        # TODO: generalize 'entries' parameter values
        if mode == 'zfs':
            cmd = "select * from zfs_replications where source_dataset='%s' and target_ip='%s' and target_pool='%s'" % (
                entries['source_dataset'], entries['target_ip'], entries['target_pool'])
            replications, err = db.get_multiple_rows(db_path, cmd)
            if err:
                raise Exception(err)
        elif mode == 'rsync':
            cmd = "select * from rsync_replications where source_path='%s' and target_ip='%s' and target_path='%s'" % (
                entries['source_path'], entries['target_ip'], entries['target_path'])
            replications, err = db.get_multiple_rows(db_path, cmd)
            if err:
                raise Exception(err)

        if replications is not None:
            for replication in replications:
                repl, err = get_remote_replications(
                    replication['remote_replication_id'])
                if err:
                    raise Exception(err)
                repls.append(repl)

    except Exception, e:
        return None, 'Error retrieving remote replications : %s' % e
    else:
        return repls, None


def compile_report():
    l = []
    try:
        from reportlab.platypus import Paragraph
        from reportlab.lib.styles import getSampleStyleSheet
        styles = getSampleStyleSheet()

        rr_list, err = get_remote_replications()
        if err:
            raise Exception(err)
        if rr_list and rr_list[0]:
            for idx, rr in enumerate(rr_list, start=1):
                task, err = tasks_utils.get_tasks_by_cron_task_id(rr['cron_task_id'], get_last_by='initiate_time')
                if err:
                    raise Exception(err)
                if task and task[0]:
                    task = task[0]
                    rep = {}
                    rep['sno'] = idx
                    rep['description'] = '\n'.join(wrap(str(rr['description']).strip(), 30))
                    rep['mode'] = str(rr['mode'])
                    rep['run_schedule'] = '\n'.join(wrap(str(rr['schedule_description']).strip(), 20))
                    rep['pause_schedule'] = '\n'.join(wrap(str(rr['pause_schedule_description']).strip(), 20))
                    rep['status'] = str(task['status'])
                    rep['initiate_time'] = task['initiate_time']
                    rep['last_run_time'] = task['last_run_time']
                    rep['misc'] = ''

                    initiate_time_str, err = datetime_utils.convert_from_epoch(
                        task['initiate_time'], return_format='str', str_format='%c', to='local')
                    if not err:
                        rep['initiate_time'] = '\n'.join(wrap(initiate_time_str, 10))
                    last_run_time_str, err = datetime_utils.convert_from_epoch(
                        task['last_run_time'], return_format='str', str_format='%c', to='local')
                    if not err:
                        rep['last_run_time'] = '\n'.join(wrap(last_run_time_str, 10))

                    if rep['mode'] == 'rsync':
                        logs_path, err = config.get_tasks_log_dir_path()
                        if (not err) and logs_path:
                            ret, err = command.get_command_output("tail -n40 %s/%s.log 2> /dev/null" % (logs_path, task['task_id']), check_rc=False, shell=True)
                            if (not err) and ret:
                                log_str = ''
                                extracts = []
                                substr_list =[]
                                substr_list.append("Number of files:")
                                substr_list.append("Number of files transferred:")
                                substr_list.append("Total file size:")
                                substr_list.append("Total transferred file size:")
                                substr_list.append("Total bytes sent:")
                                substr_list.append("Total bytes received:")
                                substr_list.append("Synced snapshots")
                                substr_list.append("Could not sync snapshots")
                                for entry in ret:
                                    extracts += [ entry.strip() for substr in substr_list if substr in entry]
                                if extracts:
                                    text = ''
                                    for entry in extracts:
                                        text += '%s\n<br/>' % entry
                                        """
                                        entry = '%s - ' % entry
                                        log_str += '\n'.join(wrap(str(entry), 20))
                                        """
                                    log_str = Paragraph('<para align=left spaceb=3>%s</para>' % text, styles['BodyText'])
                                rep['misc'] = log_str

                    l.append(rep)

    except Exception, e:
        return None, 'Could not compile replication report: %s' % e
    else:
        return l, None


def generate_pdf_report():
    try:
        from reportlab.lib import colors
        from reportlab.lib.units import inch
        from reportlab.lib.pagesizes import A3
        from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph
        from reportlab.lib.styles import getSampleStyleSheet

        report, err = compile_report()
        if err:
            raise Exception(err)

        epoch, err = datetime_utils.get_epoch()
        curr, err = datetime_utils.convert_from_epoch(
            epoch, return_format='str', str_format='%Y%m%d-%H%M%S', to='local')
        name = 'remote-replication-%s' % curr

        reports_path, err = config.get_remote_replication_reports_dir_path()
        if err:
            raise Exception(err)
        report_path = '%s/%s.pdf' % (reports_path, name)

        doc = SimpleDocTemplate(report_path, pagesize=A3)

        elements = []
        styles = getSampleStyleSheet()

        elements.append(Paragraph('''
            <para align=center spaceb=3>IntegralSTOR: Remote replications report
            </para>''', styles['Heading1']))

        host_name, err = networking.get_hostname()
        domain_name, err = networking.get_domain_name()

        org_info = ''
        org_d, err = system_info.get_org_info()
        if org_d:
            if org_d['org_name']:
                org_info = 'Organization name: %s<br/>' % org_d['org_name']
            if org_d['unit_name']:
                org_info = '%sUnit name: %s<br/>' % (org_info, org_d['unit_name'])
            if org_d['unit_id']:
                org_info = '%sUnit ID: %s<br/>' % (org_info, org_d['unit_id'])
            if org_d['subunit_name']:
                org_info = '%sSubunit name: %s<br/>' % (org_info, org_d['subunit_name'])
            if org_d['subunit_id']:
                org_info = '%sSubunit ID: %s<br/>' % (org_info, org_d['subunit_id'])
        description = '%s<br/>Host: %s.%s<br/>' % (org_info, host_name, domain_name)
        epoch, err = datetime_utils.get_epoch()
        curr, err = datetime_utils.convert_from_epoch(
            epoch, return_format='str', str_format='%Y-%m-%d at %H:%M:%S', to='local')
        description = '%sGenerated on %s <br/>' % (description, curr)
        description = '%s<br/><br/>' % description
        elements.append(Paragraph(
            '<para align=left spaceb=3>%s</para>' % description, styles['Normal']))

        data = []
        l = ['S.NO.',
             'DESCRIPTION',
             'MODE',
             'RUN SCHEDULE',
             'PAUSE SCHEDULE',
             'STATUS',
             'INITIATED AT',
             'LAST RUN AT',
             'MISC. INFO']
        data.append(l)

        for r in report:
            l = [r['sno'],
                 r['description'],
                 r['mode'],
                 r['run_schedule'],
                 r['pause_schedule'],
                 r['status'],
                 r['initiate_time'],
                 r['last_run_time'],
                 r['misc']]
            data.append(l)

        t = Table(data, repeatRows=1)
        t.setStyle(TableStyle([('BOX', (0, 0), (-1, -1), 2, colors.black),
                               ('INNERGRID', (0, 0), (-1, -1), 0.25, colors.black),
                               ('LINEABOVE', (0, 1), (-1, 1), 2, colors.black),
                               ('BACKGROUND', (0, 0), (-1, 0), colors.lavender),
                               ('FONT', (0, 0), (-1, 0), 'Helvetica-Bold'),
                               ('LEFTPADDING', (0, 0), (-1, -1), 3),
                               ('RIGHTPADDING', (0, 0), (-1, -1), 3),
                               ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                               ('ALIGN', (-1, 1), (-1, -1), 'LEFT'),
                               ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'), ]))
        t._argW[8] = 2.5*inch
        elements.append(t)
        if not report:
            elements.append(Paragraph('''
                <para align=center spaceb=3>\n\nNo remote replications
                </para>''', styles['Heading3']))

        doc.build(elements)

    except Exception, e:
        return None, 'Could not generate PDF: %s' % e
    else:
        return True, None


def run_rsync_remote_replication(remote_replication_id):
    """Creates the replication task in tasks table and executes(runs) it

    """
    try:
        scripts_path, err = config.get_shell_scripts_path()
        if err:
            raise Exception(err)
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        rr_info, err = get_remote_replications(remote_replication_id)
        if err:
            raise Exception('Could not fetch replication details: %s' % err)
        replication = rr_info[0]
        mode = replication['mode']
        if mode != 'rsync':
            raise Exception('Replication mode mismatch')

        # replications that involve interactions with remote machines
        # are done as 'replicator' user.
        # Requires SSH key exchange to successfully get through with
        # the communications
        # NOTE: SSH key exchange is not handled here

        description = replication['description']
        rsync_entries = replication['rsync'][0]
        rsync_type = rsync_entries['rsync_type']
        source_path = None
        source_path_live = rsync_entries['source_path']
        target_path = rsync_entries['target_path']
        short_switches = rsync_entries['short_switches']
        long_switches = rsync_entries['long_switches']
        remote_ip = rsync_entries['target_ip']
        remote_user_name = rsync_entries['target_user_name']
        run_as_user_name = 'replicator'

        rr, err = get_remote_replications_with('rsync',
                                               {'source_path': source_path_live, 'target_ip': remote_ip, 'target_path': target_path})
        if err:
            raise Exception(err)
        if not rr:
            raise Exception(
                'Could not locate the specified remote replication task')
        # Check for active replication tasks
        is_running, err = tasks_utils.is_task_running(
            rr[0][0]['cron_task_id'], 4, True)
        if err:
            raise Exception(err)
        if is_running is True:
            audit_str = "Did not commence replication: %s. A background task with the same description is yet to complete its replication!" % description
            audit.audit("task_fail", audit_str, None, system_initiated=True)
            raise Exception(audit_str)

        zfs_source_snap = None
        rename_snap_cmd = ''
        create_snap_cmd = ''
        if rsync_entries['is_between_integralstor'] == 'True':
            zfs_source_snap, err = sync_snapshot_prior_rsync(
                remote_replication_id)
            if err:
                raise Exception(err)
            post_run_cmds, err = get_snapshot_sync_cmd_post_rsync(
                remote_replication_id, zfs_source_snap)
            if err:
                raise Exception(err)
            rename_snap_cmd = post_run_cmds['rename_snap_cmd']
            create_snap_cmd = post_run_cmds['create_snap_cmd']
        if rsync_entries['is_between_integralstor'] is 'True' and zfs_source_snap is None:
            raise Exception('Snapshot name is required')

        # if snapshot name is provided, include its path
        if zfs_source_snap is not None:
            snap_path = '.zfs/snapshot/%s' % zfs_source_snap
            # split by '/' to get all directory names in the path
            dirs = [i for i in source_path_live.split('/')]
            # dirs[0] will be an empty string, keep it.
            # dirs[1] will be pool name
            # dirs[2] will be filesystem name
            dirs.insert(3, snap_path)
            source_path = '/'.join(dirs)
        else:
            source_path = source_path_live

        paths, err = rsync.form_rsync_paths_command(
            rsync_type, source_path, target_path, remote_ip, remote_user_name)
        if err:
            raise Exception(err)
        source = paths['source_path']
        target = paths['target_path']

        cmd_arg = ''
        if rsync_type in ['push', 'pull']:
            cmd_arg = 'sudo rsync -hi %s %s --stats -e \\"ssh -l %s -i /home/%s/.ssh/id_rsa -o UserKnownHostsFile=/home/%s/.ssh/known_hosts -o ServerAliveInterval=300 -o ServerAliveCountMax=3\\" %s %s' % (
                short_switches, long_switches, run_as_user_name, run_as_user_name, run_as_user_name, source, target)
        elif rsync_type in ['local']:
            cmd_arg = 'rsync -hi %s %s --stats %s %s' % (
                short_switches, long_switches, source, target)

        path = '%s/rsync_replicator.sh' % scripts_path
        # execute with a new session so that all the descendants fall
        # within a single session. Helps tag and kill them later.
        cmd = 'setsid /bin/bash %s "%s" "%s" "%s" "%s"' % (path,
                                                    cmd_arg, rename_snap_cmd, create_snap_cmd, remote_replication_id)

        # Retry upto 3 times(default) with a retry interval of 1 hour
        # If one shot replication, attemps should be 1
        attempts = 3
        if replication['is_one_shot'] == 'True':
            attempts = 1

        task_id, err = tasks_utils.create_task(description, [
            {'Replication': cmd}], task_type_id=4, run_as_user_name=run_as_user_name, attempts=attempts, retry_interval=60, cron_task_id=rr[0][0]['cron_task_id'])
        if err:
            raise Exception(err)

        # Now run it
        ret, err = tasks_utils.run_task(task_id)

        # If it is one shot replication, remove the remote replication
        # entry because it is not required anymore.
        if replication['is_one_shot'] == 'True':
            is_del, del_err = delete_remote_replication(int(remote_replication_id))
            if del_err:
                raise Exception("%s \n%s" % (del_err, err))

        # Now check if run_task() returned any error
        if err:
            raise Exception(err)
    except Exception, e:
        return False, 'Error processing/executing rsync remote replication: %s' % e
    else:
        return True, None


def run_zfs_remote_replication(remote_replication_id):
    """Creates the replication task in tasks table and executes(runs) it

    """
    try:
        scripts_path, err = config.get_shell_scripts_path()
        if err:
            raise Exception(err)
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        rr_info, err = get_remote_replications(remote_replication_id)
        if err:
            raise Exception('Could not fetch replication details: %s' % err)

        # replications that involve interactions with remote machines
        # are done as 'replicator' user.
        # Requires SSH key exchange to successfully get through with
        # the communications
        # NOTE: SSH key exchange is not handled here
        replication = rr_info[0]
        mode = replication['mode']
        if mode != 'zfs':
            raise Exception('Replication mode mismatch')

        description = replication['description']
        zfs_entries = replication['zfs'][0]
        source_dataset = zfs_entries['source_dataset']
        target_ip = zfs_entries['target_ip']
        target_pool = zfs_entries['target_pool']
        target_user_name = zfs_entries['target_user_name']
        run_as_user_name = 'replicator'

        pos = source_dataset.find("/")
        if pos == -1:
            raise Exception('Invalid dataset name')
        source_pool = source_dataset[:pos]
        source_dataset_name = source_dataset[(pos + 1):]

        rr, err = get_remote_replications_with('zfs',
                                               {'source_dataset': source_dataset, 'target_ip': target_ip, 'target_pool': target_pool})
        if err:
            raise Exception(err)
        if not rr:
            raise Exception(
                'Could not locate the specified remote replication task')

        # Check for active replication tasks
        is_running, err = tasks_utils.is_task_running(
            rr[0][0]['cron_task_id'], 4, True)
        if err:
            raise Exception(err)
        if is_running is True:
            audit_str = "Did not commence replication: %s. A background task with the same description is yet to complete its replication!" % description
            audit.audit("task_fail", audit_str, None, system_initiated=True)
            raise Exception(audit_str)

        path = '%s/zfs_replicator.sh' % scripts_path
        # execute with a new session so that all the descendants fall
        # within a single session. Helps tag and kill them later.
        cmd = "setsid /bin/bash %s %s %s %s %s %s %s" % (
            path, source_pool, source_dataset_name, target_pool, target_user_name, target_ip, remote_replication_id)

        # Retry upto 3 times(default) with a retry interval of 1 hour
        # If one shot replication, attemps should be 1
        attempts = 3
        if replication['is_one_shot'] == 'True':
            attempts = 1

        task_id, err = tasks_utils.create_task(description, [
            {'Replication': cmd}], task_type_id=4, run_as_user_name=run_as_user_name, attempts=attempts, retry_interval=60, cron_task_id=rr[0][0]['cron_task_id'])
        if err:
            raise Exception(err)

        # Now run it
        ret, err = tasks_utils.run_task(task_id)

        # If it is one shot replication, remove the remote replication
        # entry because it is not required anymore.
        if replication['is_one_shot'] == 'True':
            is_del, del_err = delete_remote_replication(int(remote_replication_id))
            if del_err:
                raise Exception("%s \n%s" % (del_err, err))

        # Now check if run_task() returned any error
        if err:
            raise Exception(err)

    except Exception, e:
        return False, 'Error processing/executing ZFS remote replication: %s' % e
    else:
        return True, None


if __name__ == "__main__":
    # print schedule_remote_replication("Replication of try-try/send to pool zpool on machine 192.168.1.212", "try-try/send", "192.168.1.212", "replicator", "zpool")
    # print schedule_remote_replication("Replication of try-try/send to pool
    # zpool on machine 192.168.1.212","test-pool/test-send", "192.168.1.129",
    # "replicator", "p1")
    # def schedule_remote_replication(description, mode, entries):
    # print schedule_remote_replication("Replication of try-try/ds to pool dd
    # on machine 12.12.12.12", 'zfs', {'source_dataset':'try-try/ds',
    # 'target_ip':'12.12.12.12', 'target_user_name':'replicator',
    # 'target_pool':'dd'})
    # print get_remote_replications(1)
    # print sync_snapshot_prior_rsync(6)
    # print get_snapshot_sync_cmd_post_rsync(5, "rrr_tmp")
    # print get_source_target_fs_names(8)
    # print run_rsync_remote_replication(8)
    # print compile_report()
    print generate_pdf_report()
    pass

# vim: tabstop=8 softtabstop=0 expandtab ai shiftwidth=4 smarttab
